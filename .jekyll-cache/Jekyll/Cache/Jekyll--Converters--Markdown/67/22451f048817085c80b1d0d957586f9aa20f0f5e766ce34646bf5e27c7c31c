I"R<h3 id="joint-compatibility-branch-and-bound">Joint Compatibility Branch and Bound</h3>
<p>While coarse-level data association helps us identify which clusters of LiDAR points are associated with which objects (and which ones are possibly of new objects), in order to update the state of our currently tracked objects, we need to perform point-to-point matching. Successfully performing this matching is critical to the entire system, since we use these matches to estimate a transformation that is used to update the state of our tracked objects.</p>

<p>In fine-level data association, we perform such matching. The core algorithm in this stage is the Joint Compatibility Branch and Bound (JCBB) algorithm, a common algorithm used for MOT (multi-object tracking) data association. In the JCBB algorithm, we run a depth first search to find a joint data association that minimizes jNIS (the joint normalized innovation squared).
The formula for jNIS is as follows. Say we have a set of measurements z<sub>σ</sub> that we propose are associated with a set of currently estimated boundary points h<sub>σ</sub>. The joint pairing has an innovation covariance of:</p>

<p><img src="/assets/join_paring_covariance.png" alt="join_paring_covariance" /></p>

<p>Where P is the covariance of the track, R is the expected measurement noise of the LiDAR, and Hσ is the Jacobian of the measurement model of the boundary points. Then, the jNIS is:</p>

<p>jNIS = (z<sub>σ</sub> - h<sub>σ</sub>)<sup>T</sup> S<sup>-1</sup><sub>σ</sub>(z<sub>σ</sub> - h<sub>σ</sub>)</p>

<p>This formula is similar to the <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Mahalanobis distance</a>, which measures the distance between two probability distributions.</p>

<h3 id="transformation-estimation">Transformation Estimation</h3>
<p>Fine association outputs a set of paired scan points and currently estimated boundary points. These pairs are used to update the hidden state of our tracks.
To do this, we diverge from the paper, and use these pair points to estimate a transformation T between the estimated boundary points and scan points. Given that we know the timestep between observations, we can use T to create a fictious measurement of the track’s position, orientation, and velocity.
A rigid body transformation is appropriate in this use-case, as we are designing this system for F1Tenth racing, where the only tracks we will likely encounter are other cars, walls, or cones, all relatively rigid objects. This assumption, however, may not be appropriate if this system were deployed on a vehicle that may observe non-rigid objects like humans or animals.
As we are estimating a 2D rigid body transformation, T will simply be a 3x3 matrix that encodes the SE(2) transformation that best maps our scan points to our estimated boundary points. To best estimate this transformation, we can either estimate a least squares solution to calculate the transformation matrix between the entire set of pairs via the Kabsch algorithm, or as a cheaper alternative which performs better when the number of pairs is high, run RANSAC, and compute the transformation matrix for a minibatch of pairs (via Kabsch), keeping the transformation that generates the highest number of inliers on the entire set of pairs.</p>

<p><img src="/assets/ransac.png" alt="RANSAC" /></p>

<p>Once the transformation matrix is estimated, it can be used to approximate the fictious measurement by assuming that the transformation occurred as the track was moving with a constant linear and angular velocity.</p>

<p><img src="/assets/transformation_estimation.png" alt="transformation_estimation" /></p>

<h3 id="measurement-model">Measurement Model</h3>
<p>Our “fictious” measurements can be thought of direct observations of the position, velocity, and orientation of tracked objects. These measurements, however, are quite noisy, as data association and transformation estimation both are inherently noisy processes. As such, our measurement model can be thought of as following the below equation, where R is a diagonal noise covariance matrix. In particular, the terms in R associated with velocity (angular and linear) have noise terms that are larger than those associated with position, as velocity estimation is likely to be more noisy that position estimation.</p>

<p><img src="/assets/measurement_model.png" alt="RANSmeasurement_modelAC" /></p>
:ET